{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Vault of vaults strategy\n",
    "\n",
    "- Based on `08`\n",
    "- Use new, alternative, allocation method which combines TVL threshold and max positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Set up\n",
    "\n",
    "Set up Trading Strategy data client.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T08:48:16.546848Z",
     "start_time": "2024-07-19T08:48:16.464970Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from tradingstrategy.client import Client\n",
    "from tradeexecutor.utils.notebook import setup_charting_and_output, OutputMode, set_notebook_logging\n",
    "\n",
    "client = Client.create_jupyter_client()\n",
    "\n",
    "# Set up drawing charts in interactive vector output mode.\n",
    "# This is slower. See the alternative commented option below.\n",
    "# setup_charting_and_output(OutputMode.interactive)\n",
    "\n",
    "# Set up rendering static PNG images.\n",
    "# This is much faster but disables zoom on any chart.\n",
    "setup_charting_and_output(OutputMode.static, image_format=\"png\", width=1500, height=1000)\n",
    "\n",
    "\n",
    "logger = logging.getLogger(\"strategy\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain configuration\n",
    "\n",
    "- Choose target chains and their vults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eth_defi.token import USDC_NATIVE_TOKEN\n",
    "from eth_defi.token import USDT_NATIVE_TOKEN\n",
    "from eth_defi.token import WRAPPED_NATIVE_TOKEN\n",
    "\n",
    "from tradingstrategy.chain import ChainId\n",
    "from tradingstrategy.lending import LendingProtocolType\n",
    "\n",
    "CHAIN_ID = ChainId.arbitrum\n",
    "\n",
    "\n",
    "# We define our main trading universe,\n",
    "# and then Ethereum mainnet as a validation set\n",
    "match CHAIN_ID:\n",
    "    case ChainId.arbitrum:\n",
    "\n",
    "        EXCHANGES = (\"uniswap-v2\", \"uniswap-v3\")\n",
    "        SUPPORTING_PAIRS = [\n",
    "            (ChainId.arbitrum, \"uniswap-v3\", \"WETH\", \"USDC\", 0.0005),\n",
    "        ]\n",
    "        LENDING_RESERVES = None\n",
    "        PREFERRED_STABLECOIN = USDC_NATIVE_TOKEN[CHAIN_ID].lower()\n",
    "\n",
    "\n",
    "        VAULTS = [\n",
    "            (ChainId.arbitrum, \"0x58bfc95a864e18e8f3041d2fcd3418f48393fe6a\"), # Plutus Hedge Token\n",
    "            (ChainId.arbitrum, \"0x959f3807f0aa7921e18c78b00b2819ba91e52fef\"), # gmUSDC\n",
    "            (ChainId.arbitrum, \"0xd3443ee1e91af28e5fb858fbd0d72a63ba8046e0\"), # gTrade (Gains) USDC\n",
    "            (ChainId.arbitrum, \"0x75288264fdfea8ce68e6d852696ab1ce2f3e5004\"), # Hype++\n",
    "            (ChainId.arbitrum, \"0x4b6f1c9e5d470b97181786b26da0d0945a7cf027\"), # Hypertrim USDC\n",
    "            (ChainId.arbitrum, \"0x0b2b2b2076d95dda7817e785989fe353fe955ef9\"), # Staked USDai\n",
    "            (ChainId.arbitrum, \"0x64ca76e2525fc6ab2179300c15e343d73e42f958\"), # Clearstar high yielsd USDC\n",
    "            (ChainId.arbitrum, \"0x7e97fa6893871a2751b5fe961978dccb2c201e65\"), # Gauntlet\n",
    "            (ChainId.arbitrum, \"0x1a996cb54bb95462040408c06122d45d6cdb6096\"), # Fluid\n",
    "            (ChainId.arbitrum, \"0xa91267a25939b2b0f046013fbf9597008f7f014b\"), # IPOR USDC Arbirum optimise\n",
    "            (ChainId.arbitrum, \"0x05d28a86e057364f6ad1a88944297e58fc6160b3\"), # Euler Arbitrum Yield USDC \n",
    "            (ChainId.arbitrum, \"0x20d419a8e12c45f88fda7c5760bb6923cee27f98\"), # Ostium liquidity provider\n",
    "            (ChainId.arbitrum, \"0x444868b6e8079ac2c55eea115250f92c2b2c4d14\"), # Dolomite\n",
    "            (ChainId.arbitrum, \"0x9fa306b1f4a6a83fec98d8ebbabedff78c407f6b1\"), # USDC-2 yVault\n",
    "            (ChainId.arbitrum, \"0x940098b108fb7d0a7e374f6eded7760787464609\"),  # Spark USDC\n",
    "            (ChainId.arbitrum, \"0xb01a958d8e9dba566c6d71f66ef566ccf5fac859\"),  # Harvest USDC\n",
    "            (ChainId.arbitrum, \"0x98c49e13bf99d7cad8069faa2a370933ec9ecf17\"),  # Summerfi USDT\n",
    "\n",
    "            # Some smaller entries to mix in\n",
    "            # (ChainId.arbitrum, \"0xc8248953429d707c6a2815653eca89846ffaa63b\"), # Curve LLAMMA asdCRV / crvUSD\n",
    "            (ChainId.arbitrum, \"0xf63b7f49b4f5dc5d0e7e583cfd79dc64e646320c\"), # Auto finance Tokemak ARB/USDC\n",
    "            # (ChainId.arbitrum, \"0xeeaf2ccb73a01deb38eca2947d963d64cfde6a32\"), # Curve LLAMMA CRV / crvUSD\n",
    "            (ChainId.arbitrum, \"0xe5d6eb448ac5a762c1ebe8cd1692b9cd08025176\"), # DAMM stablecoin fund\n",
    "\n",
    "        ]        \n",
    "\n",
    "        BENCHMARK_PAIRS = [\n",
    "            (ChainId.arbitrum, \"uniswap-v3\", \"WETH\", \"USDC\", 0.0005),\n",
    "        ]\n",
    "\n",
    "        # Exclude Euro vaults, etc.\n",
    "        # ALLOWED_VAULT_DENOMINATION_TOKENS = {\"USDC\", \"USDT\", \"USDC.e\"}\n",
    "        ARBITRUM_STABLECOIN_ADDRESSES = {\n",
    "            \"USDC\": \"0xaf88d065e77c8cC2239327C5EDb3A432268e5831\",\n",
    "            \"USDT\": \"0xFd086bC7CD5C481DCC9C85ebE478A1C0b69FCbb9\",\n",
    "            \"USDC.e\": \"0xff970a61a04b1ca14834a43f5de4533ebddb5cc8\",\n",
    "            # \"crvUSD\": \"0x498bf2b1e120fed3ad3d42ea2165e9b73f99c1e5\",\n",
    "            \"USDai\": \"0x0A1a1A107E45b7Ced86833863f482BC5f4ed82EF\",\n",
    "            \"USDâ‚®0\": \"0xFd086bC7CD5C481DCC9C85ebE478A1C0b69FCbb9\",  # Same as USDT\n",
    "        }\n",
    "        ALLOWED_VAULT_DENOMINATION_TOKENS = set(ARBITRUM_STABLECOIN_ADDRESSES.keys())\n",
    "    \n",
    "    case ChainId.base:\n",
    "        raise NotImplementedError()\n",
    "    case ChainId.ethereum:\n",
    "        raise NotImplementedError()\n",
    "    case ChainId.binance:\n",
    "        raise NotImplementedError()\n",
    "    case ChainId.avalanche:\n",
    "        raise NotImplementedError()\n",
    "    case _:\n",
    "        raise NotImplementedError(f\"Chain not supported: {CHAIN_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Parameters\n",
    "\n",
    "- Collection of parameters used in the calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T08:48:16.558597Z",
     "start_time": "2024-07-19T08:48:16.556375Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from tradingstrategy.timebucket import TimeBucket\n",
    "from tradeexecutor.strategy.cycle import CycleDuration\n",
    "from tradeexecutor.strategy.parameters import StrategyParameters\n",
    "from tradeexecutor.strategy.default_routing_options import TradeRouting\n",
    "\n",
    "from tradeexecutor.utils.jupyter_notebook_name import get_notebook_id\n",
    "\n",
    "\n",
    "class Parameters:\n",
    "\n",
    "    id = get_notebook_id(globals())\n",
    "\n",
    "    # We trade 1h candle\n",
    "    candle_time_bucket = TimeBucket.d1\n",
    "    cycle_duration = CycleDuration.cycle_7d\n",
    "    \n",
    "    chain_id = CHAIN_ID\n",
    "    exchanges = EXCHANGES\n",
    "    \n",
    "    #\n",
    "    # Basket size, risk and balancing parametrs.\n",
    "    #   \n",
    "    min_asset_universe = 6  # How many assets we need in the asset universe to start running the index\n",
    "    max_assets_in_portfolio = 7  # How many assets our basket can hold once\n",
    "    allocation = 0.95  # Allocate all cash to volatile pairs\n",
    "    # min_rebalance_trade_threshold_pct = 0.05  # % of portfolio composition must change before triggering rebalacne\n",
    "    individual_rebalance_min_threshold_usd = 500.0  # Don't make buys less than this amount\n",
    "    sell_rebalance_min_threshold = 100.0\n",
    "    sell_threshold = 0.05  # Sell if asset is more than 5% of the portfolio\n",
    "    per_position_cap_of_pool = 0.33  # Never own more than % of the lit liquidity of the trading pool\n",
    "    max_concentration = 0.33 # How large % can one asset be in a portfolio once\n",
    "    min_portfolio_weight = 0.0050  # Close position / do not open if weight is less than 50 BPS\n",
    "\n",
    "    # How long rolling returns window in bars (days)\n",
    "    # Needed to calculate weights\n",
    "    rolling_returns_bars = 35\n",
    "\n",
    "    min_tvl = 50_000  # Minimum TVL in the vault before it can be considered investable\n",
    "\n",
    "    #     \n",
    "    #\n",
    "    # Backtesting only\n",
    "    # Limiting factor: Aave v3 on Base starts at the end of DEC 2023\n",
    "    #\n",
    "    backtest_start = datetime.datetime(2025, 1, 1)\n",
    "    backtest_end = datetime.datetime(2025, 7, 1)\n",
    "    initial_cash = 100_000\n",
    "\n",
    "    #\n",
    "    # Live only\n",
    "    #\n",
    "    routing = TradeRouting.default\n",
    "    required_history_period = datetime.timedelta(days=365*3)\n",
    "    slippage_tolerance = 0.0060  # 0.6% \n",
    "    assummed_liquidity_when_data_missings = 10_000\n",
    "    \n",
    "\n",
    "parameters = StrategyParameters.from_class(Parameters)  # Convert to AttributedDict to easier typing with dot notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Trading pairs and market data\n",
    "\n",
    "- This creates the strategy universe containing pair metadata and their prices\n",
    "- The universe is \"masked\" by simply selecting pairs on the predefined pairs list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T08:48:18.342247Z",
     "start_time": "2024-07-19T08:48:16.556521Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "from typing import Callable\n",
    "from tradingstrategy.pair import PandasPairUniverse\n",
    "\n",
    "\n",
    "from eth_defi.vault.vaultdb import DEFAULT_RAW_PRICE_DATABASE\n",
    "\n",
    "from tradingstrategy.utils.token_filter import add_base_quote_address_columns\n",
    "from tradingstrategy.utils.token_filter import filter_for_exchange_slugs\n",
    "from tradingstrategy.utils.token_filter import filter_pairs_default\n",
    "from tradingstrategy.utils.token_filter import filter_for_selected_pairs\n",
    "from tradingstrategy.utils.token_extra_data import load_token_metadata\n",
    "from tradingstrategy.utils.token_filter import deduplicate_pairs_by_volume\n",
    "from tradingstrategy.utils.token_extra_data import load_token_metadata\n",
    "from tradingstrategy.alternative_data.vault import load_vault_database\n",
    "\n",
    "\n",
    "from tradeexecutor.strategy.trading_strategy_universe import TradingStrategyUniverse\n",
    "from tradeexecutor.strategy.execution_context import ExecutionContext, notebook_execution_context\n",
    "from tradeexecutor.strategy.universe_model import UniverseOptions\n",
    "from tradeexecutor.strategy.trading_strategy_universe import TradingStrategyUniverse, load_partial_data\n",
    "from tradeexecutor.strategy.execution_context import ExecutionContext, notebook_execution_context\n",
    "from tradeexecutor.strategy.universe_model import UniverseOptions\n",
    "from tradeexecutor.analysis.pair import display_strategy_universe\n",
    "from tradeexecutor.strategy.pandas_trader.trading_universe_input import CreateTradingUniverseInput\n",
    "from tradeexecutor.analysis.vault import display_vaults\n",
    "\n",
    "\n",
    "\n",
    "# Hack to support vault data exposure to live trading universe creation\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)  # Loads variables from .env file\n",
    "\n",
    "\n",
    "def create_trading_universe(\n",
    "    input: CreateTradingUniverseInput,\n",
    ") -> TradingStrategyUniverse:\n",
    "    \"\"\"Create the trading universe.\n",
    "\n",
    "    - Load Trading Strategy full pairs dataset\n",
    "\n",
    "    - Load built-in Coingecko top 1000 dataset\n",
    "\n",
    "    - Get all DEX tokens for a certain Coigecko category\n",
    "\n",
    "    - Load OHCLV data for these pairs\n",
    "\n",
    "    - Load also BTC and ETH price data to be used as a benchmark\n",
    "    \"\"\"\n",
    "\n",
    "    execution_context = input.execution_context\n",
    "    client = input.client\n",
    "    timestamp = input.timestamp\n",
    "    parameters = input.parameters or Parameters  # Some CLI commands do not support yet passing this\n",
    "    universe_options = input.universe_options\n",
    "\n",
    "    if execution_context.live_trading:\n",
    "        # Live trading, send strategy universe formation details\n",
    "        # to logs\n",
    "        debug_printer = logger.info\n",
    "    else:\n",
    "        # Jupyter notebook inline output\n",
    "        debug_printer = print\n",
    "\n",
    "    chain_id = parameters.chain_id\n",
    "\n",
    "    debug_printer(f\"Preparing trading universe on chain {chain_id.get_name()}\")\n",
    "\n",
    "    # Pull out our benchmark pairs ids.\n",
    "    # We need to construct pair universe object for the symbolic lookup.\n",
    "    # TODO: PandasPairUniverse(buidl_index=True) - speed this up by skipping index building\n",
    "    all_pairs_df = client.fetch_pair_universe().to_pandas()\n",
    "    pairs_df= filter_for_selected_pairs(\n",
    "        all_pairs_df,\n",
    "        SUPPORTING_PAIRS,\n",
    "    )    \n",
    "\n",
    "    debug_printer(f\"We have total {len(all_pairs_df)} pairs in dataset and going to use {len(pairs_df)} pairs for the strategy\")\n",
    "\n",
    "    # Check which vaults we can include based on allowed deposit tokens for this backtest\n",
    "    vault_universe = load_vault_database()\n",
    "    total_vaults = vault_universe.get_vault_count()\n",
    "    vault_universe = vault_universe.limit_to_vaults(VAULTS, check_all_vaults_found=False)\n",
    "    vault_universe = vault_universe.limit_to_denomination(ALLOWED_VAULT_DENOMINATION_TOKENS, check_all_vaults_found=True)\n",
    "    debug_printer(f\"Loaded total {vault_universe.get_vault_count()} vaults from the total of {total_vaults} in vault database\")\n",
    "\n",
    "    # Default vault data bundle path for backtesting\n",
    "    vault_bundled_price_data = DEFAULT_RAW_PRICE_DATABASE\n",
    "    debug_printer(f\"Using vault price data for backtesting from {vault_bundled_price_data}\")\n",
    "\n",
    "    dataset = load_partial_data(\n",
    "        client=client,\n",
    "        time_bucket=parameters.candle_time_bucket,\n",
    "        pairs=pairs_df,\n",
    "        execution_context=execution_context,\n",
    "        universe_options=universe_options,\n",
    "        liquidity=True,\n",
    "        liquidity_time_bucket=TimeBucket.d1,\n",
    "        lending_reserves=LENDING_RESERVES,\n",
    "        vaults=vault_universe,\n",
    "        vault_bundled_price_data=vault_bundled_price_data if not execution_context.live_trading else None,\n",
    "        check_all_vaults_found=True,\n",
    "    )\n",
    "\n",
    "    debug_printer(\"Creating strategy universe with price feeds and vaults\")\n",
    "    strategy_universe = TradingStrategyUniverse.create_from_dataset(\n",
    "        dataset,\n",
    "        reserve_asset=PREFERRED_STABLECOIN,\n",
    "        forward_fill=True,  # We got very gappy data from low liquid DEX coins\n",
    "        forward_fill_until=timestamp,\n",
    "    )\n",
    "\n",
    "    # crvUSD etc. do not have backtesting paths yet\n",
    "    strategy_universe.ignore_routing = True\n",
    "\n",
    "    # Dump our vault data and check for data errors\n",
    "    display_vaults(\n",
    "        vault_universe,\n",
    "        strategy_universe,\n",
    "        execution_mode=execution_context.mode,\n",
    "        printer=debug_printer,  \n",
    "    )\n",
    "\n",
    "    return strategy_universe\n",
    "\n",
    "\n",
    "universe_input = CreateTradingUniverseInput(\n",
    "    execution_context=notebook_execution_context,\n",
    "    client=client,\n",
    "    timestamp=None,\n",
    "    parameters=parameters,\n",
    "    universe_options=UniverseOptions.from_strategy_parameters_class(Parameters, notebook_execution_context),\n",
    "    execution_model=None,\n",
    ")\n",
    "\n",
    "strategy_universe = create_trading_universe(universe_input)\n",
    "\n",
    "\n",
    "print(\"Universe creation done\")\n",
    "\n",
    "df = display_strategy_universe(\n",
    "    strategy_universe, \n",
    "    sort_key=\"base\",\n",
    "    sort_numeric=False,\n",
    "    limit=75,\n",
    "    show_token_risk=True,\n",
    "    show_tokensniffer=True,\n",
    ")\n",
    "\n",
    "df = df.head(10)\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "html_table = df.to_html(escape=False, classes='table table-striped')\n",
    "display(HTML(html_table))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asset to trading pair map\n",
    "\n",
    "- Build a helper map\n",
    "- Because we are operating on trading pairs, not on tokens, which are the base asset of a trading pair, we set up \n",
    "  this map to easily look up the selected trading pair by its symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tradingstrategy.types import TokenSymbol\n",
    "from tradeexecutor.state.identifier import TradingPairIdentifier\n",
    "\n",
    "# Create base token symbol to pair map to help later\n",
    "# Token\n",
    "token_map: dict[TokenSymbol, TradingPairIdentifier] = {p.base.token_symbol: p for p in strategy_universe.iterate_pairs()}\n",
    "\n",
    "# Tokens part of benchmark data, but not the strategy\n",
    "benchmark_pair_ids = [p.internal_id for p in strategy_universe.iterate_pairs() if p.other_data.get(\"benchmark\") is True]\n",
    "category_pair_ids = [p.internal_id for p in strategy_universe.iterate_pairs() if p.other_data.get(\"benchmark\") is not True]\n",
    "\n",
    "print(f\"Token map is {len(token_map)} assets\")\n",
    "print(\"Category trading pairs\", len(category_pair_ids))\n",
    "print(\"Benchmark trading pairs\", len(benchmark_pair_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Indicators\n",
    "\n",
    "- Precalculate indicators used by the strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T08:48:18.342420Z",
     "start_time": "2024-07-19T08:48:18.330352Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import HTML\n",
    "import pandas_ta\n",
    "\n",
    "from tradeexecutor.strategy.pandas_trader.indicator import IndicatorSource\n",
    "from tradeexecutor.strategy.trading_strategy_universe import TradingStrategyUniverse\n",
    "from tradeexecutor.strategy.pandas_trader.indicator import calculate_and_load_indicators_inline\n",
    "from tradeexecutor.strategy.pandas_trader.indicator import IndicatorDependencyResolver\n",
    "from tradeexecutor.state.types import USDollarAmount\n",
    "from tradeexecutor.strategy.pandas_trader.indicator_decorator import IndicatorRegistry\n",
    "from tradeexecutor.analysis.indicator import display_indicators\n",
    "from tradingstrategy.utils.groupeduniverse import resample_candles\n",
    "\n",
    "\n",
    "indicators = IndicatorRegistry()\n",
    "\n",
    "empty_series = pd.Series([], index=pd.DatetimeIndex([]))\n",
    "\n",
    "\n",
    "@indicators.define()\n",
    "def rolling_returns(\n",
    "    close: pd.Series,\n",
    "    rolling_returns_bars,\n",
    ") -> pd.Series:\n",
    "    \"\"\"Calculate rolling returns over a period\n",
    "    \"\"\"\n",
    "    lagged_close = close.shift(rolling_returns_bars)\n",
    "    series = close / lagged_close - 1\n",
    "    return series\n",
    "\n",
    "\n",
    "@indicators.define(source=IndicatorSource.tvl)\n",
    "def tvl(\n",
    "    close: pd.Series,\n",
    "    execution_context: ExecutionContext,\n",
    "    timestamp: pd.Timestamp,\n",
    ") -> pd.Series:\n",
    "    \"\"\"Get TVL series for a pair.\n",
    "\n",
    "    - Because TVL data is 1d and we use 1h everywhere else, we need to forward fill\n",
    "\n",
    "    - Use previous hourly close as the value\n",
    "    \"\"\"\n",
    "    if execution_context.live_trading:\n",
    "        # TVL is daily data.\n",
    "        # We need to forward fill until the current hour.\n",
    "        # Use our special ff function.        \n",
    "        assert isinstance(timestamp, pd.Timestamp), f\"Live trading needs forward-fill end time, we got {timestamp}\"\n",
    "        from tradingstrategy.utils.forward_fill import forward_fill\n",
    "        df = pd.DataFrame({\"close\": close})\n",
    "        df_ff = forward_fill(\n",
    "            df,\n",
    "            Parameters.candle_time_bucket.to_frequency(),\n",
    "            columns=(\"close\",),\n",
    "            forward_fill_until=timestamp,\n",
    "        )\n",
    "        series = df_ff[\"close\"]\n",
    "        return series\n",
    "    else:\n",
    "        return close.resample(\"1h\").ffill()\n",
    "\n",
    "\n",
    "@indicators.define(dependencies=(tvl,), source=IndicatorSource.dependencies_only_universe)\n",
    "def tvl_inclusion_criteria(   \n",
    "    min_tvl: USDollarAmount,\n",
    "    dependency_resolver: IndicatorDependencyResolver,\n",
    ") -> pd.Series:\n",
    "    \"\"\"The pair must have min XX,XXX USD one-sided TVL to be included.\n",
    "\n",
    "    - If the Uniswap pool does not have enough ETH or USDC deposited, skip the pair as a scam\n",
    "\n",
    "    :return:\n",
    "        Series where each timestamp is a list of pair ids meeting the criteria at that timestamp\n",
    "    \"\"\"\n",
    "    \n",
    "    series = dependency_resolver.get_indicator_data_pairs_combined(tvl)\n",
    "    mask = series >= min_tvl\n",
    "    # Turn to a series of lists\n",
    "    mask_true_values_only = mask[mask == True]\n",
    "    series = mask_true_values_only.groupby(level='timestamp').apply(lambda x: x.index.get_level_values('pair_id').tolist())\n",
    "    return series\n",
    "\n",
    "\n",
    "\n",
    "@indicators.define(\n",
    "    source=IndicatorSource.strategy_universe\n",
    ")\n",
    "def trading_availability_criteria(\n",
    "    strategy_universe: TradingStrategyUniverse,\n",
    ") -> pd.Series:\n",
    "    \"\"\"Is pair tradeable at each hour.\n",
    "\n",
    "    - The pair has a price candle at that\n",
    "    - Mitigates very corner case issues that TVL/liquidity data is per-day whileas price data is natively per 1h\n",
    "      and the strategy inclusion criteria may include pair too early hour based on TVL only,\n",
    "      leading to a failed attempt to rebalance in a backtest\n",
    "    - Only relevant for backtesting issues if we make an unlucky trade on the starting date\n",
    "      of trading pair listing\n",
    "\n",
    "    :return:\n",
    "        Series with with index (timestamp) and values (list of pair ids trading at that hour)\n",
    "    \"\"\"\n",
    "    # Trading pair availability is defined if there is a open candle in the index for it.\n",
    "    # Because candle data is forward filled, we should not have any gaps in the index.\n",
    "    candle_series = strategy_universe.data_universe.candles.df[\"open\"]\n",
    "    pairs_per_timestamp = candle_series.groupby(level='timestamp').apply(lambda x: x.index.get_level_values('pair_id').tolist())\n",
    "    return pairs_per_timestamp\n",
    "\n",
    "\n",
    "@indicators.define(\n",
    "    dependencies=[\n",
    "        tvl_inclusion_criteria,\n",
    "        trading_availability_criteria\n",
    "    ],\n",
    "    source=IndicatorSource.strategy_universe\n",
    ")\n",
    "def inclusion_criteria(\n",
    "    strategy_universe: TradingStrategyUniverse,\n",
    "    min_tvl: USDollarAmount,\n",
    "    dependency_resolver: IndicatorDependencyResolver\n",
    ") -> pd.Series:\n",
    "    \"\"\"Pairs meeting all of our inclusion criteria.\n",
    "\n",
    "    - Give the tradeable pair set for each timestamp\n",
    "\n",
    "    :return:\n",
    "        Series where index is timestamp and each cell is a list of pair ids matching our inclusion criteria at that moment\n",
    "    \"\"\"\n",
    "\n",
    "    # Filter out benchmark pairs like WETH in the tradeable pair set\n",
    "    benchmark_pair_ids = set(strategy_universe.get_pair_by_human_description(desc).internal_id for desc in SUPPORTING_PAIRS)\n",
    "\n",
    "    tvl_series = dependency_resolver.get_indicator_data(\n",
    "        tvl_inclusion_criteria,\n",
    "        parameters={\n",
    "            \"min_tvl\": min_tvl,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    trading_availability_series = dependency_resolver.get_indicator_data(trading_availability_criteria)\n",
    "\n",
    "    #\n",
    "    # Process all pair ids as a set and the final inclusion\n",
    "    # criteria is union of all sub-criterias\n",
    "    #\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"tvl_pair_ids\": tvl_series,\n",
    "        \"trading_availability_pair_ids\": trading_availability_series,\n",
    "    })\n",
    "\n",
    "    # https://stackoverflow.com/questions/33199193/how-to-fill-dataframe-nan-values-with-empty-list-in-pandas\n",
    "    df = df.fillna(\"\").apply(list)\n",
    "\n",
    "    def _combine_criteria(row):\n",
    "        final_set = set(row[\"tvl_pair_ids\"]) & \\\n",
    "                    set(row[\"trading_availability_pair_ids\"])\n",
    "        return final_set - benchmark_pair_ids\n",
    "\n",
    "    union_criteria = df.apply(_combine_criteria, axis=1)\n",
    "\n",
    "    # Inclusion criteria data can be spotty at the beginning when there is only 0 or 1 pairs trading,\n",
    "    # so we need to fill gaps to 0\n",
    "    full_index = pd.date_range(\n",
    "        start=union_criteria.index.min(),\n",
    "        end=union_criteria.index.max(),\n",
    "        freq=Parameters.candle_time_bucket.to_frequency(),\n",
    "    )\n",
    "    reindexed = union_criteria.reindex(full_index, fill_value=[])\n",
    "    return reindexed\n",
    "\n",
    "\n",
    "@indicators.define(dependencies=(tvl_inclusion_criteria,), source=IndicatorSource.dependencies_only_universe)\n",
    "def tvl_included_pair_count(\n",
    "        min_tvl: USDollarAmount,\n",
    "        dependency_resolver: IndicatorDependencyResolver\n",
    ") -> pd.Series:\n",
    "    \"\"\"Calculate number of pairs in meeting volatility criteria on each timestamp\"\"\"\n",
    "    series = dependency_resolver.get_indicator_data(\n",
    "        tvl_inclusion_criteria,\n",
    "        parameters={\"min_tvl\": min_tvl},\n",
    "    )\n",
    "    series = series.apply(len)\n",
    "\n",
    "    # TVL data can be spotty at the beginning when there is only 0 or 1 pairs trading,\n",
    "    # so we need to fill gaps to 0\n",
    "    full_index = pd.date_range(\n",
    "        start=series.index.min(),\n",
    "        end=series.index.max(),\n",
    "        freq=Parameters.candle_time_bucket.to_frequency(),\n",
    "    )\n",
    "    # Reindex and fill NaN with zeros\n",
    "    reindexed = series.reindex(full_index, fill_value=0)\n",
    "    return reindexed\n",
    "\n",
    "\n",
    "@indicators.define(dependencies=(inclusion_criteria,), source=IndicatorSource.dependencies_only_universe)\n",
    "def all_criteria_included_pair_count(\n",
    "    min_tvl: USDollarAmount,\n",
    "    dependency_resolver: IndicatorDependencyResolver\n",
    ") -> pd.Series:\n",
    "    \"\"\"Series where each timestamp is the list of pairs meeting all inclusion criteria.\n",
    "\n",
    "    :return:\n",
    "        Series with pair count for each timestamp\n",
    "    \"\"\"\n",
    "    series = dependency_resolver.get_indicator_data(\n",
    "        \"inclusion_criteria\",\n",
    "        parameters={\n",
    "            \"min_tvl\": min_tvl, \n",
    "        },\n",
    "    )\n",
    "    return series.apply(len)\n",
    "\n",
    "\n",
    "@indicators.define(source=IndicatorSource.strategy_universe)\n",
    "def trading_pair_count(\n",
    "    strategy_universe: TradingStrategyUniverse,\n",
    ") -> pd.Series:\n",
    "    \"\"\"Get number of pairs that trade at each timestamp.\n",
    "\n",
    "    - Pair must have had at least one candle before the timestamp to be included\n",
    "\n",
    "    - Exclude benchmarks pairs we do not trade\n",
    "\n",
    "    :return:\n",
    "        Series with pair count for each timestamp\n",
    "    \"\"\"\n",
    "\n",
    "    benchmark_pair_ids = {strategy_universe.get_pair_by_human_description(desc).internal_id for desc in SUPPORTING_PAIRS}\n",
    "\n",
    "    # Get pair_id, timestamp -> timestamp, pair_id index\n",
    "    series = strategy_universe.data_universe.candles.df[\"open\"]    \n",
    "    swap_index = series.index.swaplevel(0, 1)\n",
    "\n",
    "    seen_pairs = set()\n",
    "    seen_data = {}\n",
    "\n",
    "    for timestamp, pair_id in swap_index:\n",
    "        if pair_id in benchmark_pair_ids:\n",
    "            continue\n",
    "        seen_pairs.add(pair_id)\n",
    "        seen_data [timestamp] = len(seen_pairs)\n",
    "\n",
    "    series = pd.Series(seen_data.values(), index=list(seen_data.keys()))\n",
    "    return series\n",
    "\n",
    "\n",
    "\n",
    "@indicators.define(\n",
    "    source=IndicatorSource.dependencies_only_per_pair,\n",
    "    dependencies=[\n",
    "        rolling_returns,\n",
    "        inclusion_criteria,\n",
    "    ]\n",
    ")\n",
    "def signal(\n",
    "    rolling_returns_bars: int,\n",
    "    candle_time_bucket: TimeBucket,\n",
    "    min_tvl: USDollarAmount,\n",
    "    pair: TradingPairIdentifier,\n",
    "    dependency_resolver: IndicatorDependencyResolver\n",
    ") -> pd.Series:\n",
    "    \"\"\"Calculate weighting criteria (\"signal\") as the past returns of the rolling returns window.\n",
    "\n",
    "    Only returns signal if the pair meets inclusion criteria at that timepoint.\n",
    "    \"\"\"\n",
    "\n",
    "    inclusion_criteria_series = dependency_resolver.get_indicator_data(\n",
    "        \"inclusion_criteria\",\n",
    "        parameters={\n",
    "            \"min_tvl\": min_tvl,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # A benchmark asset\n",
    "    if not pair.is_vault():\n",
    "        zeros = pd.Series(0, index=inclusion_criteria_series.index)\n",
    "        return zeros\n",
    "\n",
    "    rolling_returns_series = dependency_resolver.get_indicator_data(\n",
    "        \"rolling_returns\",\n",
    "        parameters={\n",
    "            \"rolling_returns_bars\": rolling_returns_bars,\n",
    "        },\n",
    "        pair=pair,\n",
    "    )\n",
    "    # return rolling_returns_series\n",
    "\n",
    "    # Create a mask where True means the pair is included at that timestamp\n",
    "    pair_id = pair.internal_id\n",
    "    inclusion_mask = inclusion_criteria_series.apply(lambda x: pair_id in x)\n",
    "    \n",
    "    smoothed_returns = rolling_returns_series.ewm(span=rolling_returns_bars).mean()\n",
    "\n",
    "    # Set signal zero for the periods when the pair was not included\n",
    "    return smoothed_returns * inclusion_mask\n",
    "\n",
    "\n",
    "display_indicators(indicators)\n",
    "\n",
    "\n",
    "# Calculate all indicators where parameters have changed and store the result on disk\n",
    "indicator_data = calculate_and_load_indicators_inline(\n",
    "    strategy_universe=strategy_universe,\n",
    "    create_indicators=indicators.create_indicators,\n",
    "    parameters=parameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trading universe charts\n",
    "\n",
    "- Define charts used in backtesting and live execution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.graph_objects import Figure\n",
    "from tradeexecutor.strategy.chart.definition import ChartRegistry, ChartKind, ChartInput\n",
    "from tradeexecutor.strategy.chart.renderer import ChartBacktestRenderingSetup\n",
    "from tradeexecutor.strategy.chart.standard.trading_universe import available_trading_pairs\n",
    "from tradeexecutor.strategy.chart.standard.trading_universe import inclusion_criteria_check \n",
    "from tradeexecutor.strategy.chart.standard.volatility import volatility_benchmark\n",
    "from tradeexecutor.strategy.chart.standard.signal import signal_comparison as _signal_comparison\n",
    "from tradeexecutor.strategy.chart.standard.signal import price_vs_signal\n",
    "from tradeexecutor.strategy.chart.standard.vault import all_vaults_share_price_and_tvl\n",
    "from tradeexecutor.strategy.chart.standard.vault import vault_position_timeline\n",
    "from tradeexecutor.strategy.chart.standard.vault import all_vault_positions\n",
    "from tradeexecutor.strategy.chart.standard.equity_curve import equity_curve\n",
    "from tradeexecutor.strategy.chart.standard.equity_curve import equity_curve_with_drawdown\n",
    "from tradeexecutor.strategy.chart.standard.performance_metrics import performance_metrics\n",
    "from tradeexecutor.strategy.chart.standard.weight import volatile_weights_by_percent\n",
    "from tradeexecutor.strategy.chart.standard.weight import volatile_and_non_volatile_percent\n",
    "from tradeexecutor.strategy.chart.standard.weight import equity_curve_by_asset\n",
    "from tradeexecutor.strategy.chart.standard.weight import weight_allocation_statistics\n",
    "from tradeexecutor.strategy.chart.standard.position import positions_at_end\n",
    "from tradeexecutor.strategy.chart.standard.thinking import last_messages\n",
    "from tradeexecutor.strategy.chart.standard.alpha_model import alpha_model_diagnostics\n",
    "from tradeexecutor.strategy.chart.standard.profit_breakdown import trading_pair_breakdown\n",
    "from tradeexecutor.strategy.chart.standard.trading_metrics import trading_metrics\n",
    "from tradeexecutor.strategy.chart.standard.interest import lending_pool_interest_accrued\n",
    "from tradeexecutor.strategy.chart.standard.interest import vault_statistics\n",
    "from tradeexecutor.strategy.chart.standard.single_pair import trading_pair_positions\n",
    "from tradeexecutor.strategy.chart.standard.single_pair import trading_pair_price_and_trades\n",
    "from tradeexecutor.strategy.chart.standard.vault import all_vaults_share_price_and_tvl as _all_vaults_share_price_and_tvl\n",
    "\n",
    "\n",
    "def equity_curve_with_benchmark(input: ChartInput) -> list[Figure]:\n",
    "    \"\"\"Add our benchmark token\"\"\"\n",
    "    return equity_curve(\n",
    "        input,\n",
    "        benchmark_token_symbols=[\"ETH\"],\n",
    "    )\n",
    "\n",
    "\n",
    "def all_vaults_share_price_and_tvl(input: ChartInput) -> list[Figure]:\n",
    "    \"\"\"Limit max_count\"\"\"\n",
    "    return _all_vaults_share_price_and_tvl(\n",
    "        input,\n",
    "        max_count=2,\n",
    "    )\n",
    "\n",
    "def signal_comparison(input: ChartInput) -> list[Figure]:\n",
    "    \"\"\"Choose vaults only\"\"\"\n",
    "\n",
    "    input = input.copy()\n",
    "    input.pairs = [p for p in input.strategy_universe.iterate_pairs() if p.is_vault()]\n",
    "    return _signal_comparison(\n",
    "        input,\n",
    "    )\n",
    "\n",
    "\n",
    "# Define charts we use in backtesting and live trading\n",
    "charts = ChartRegistry(default_benchmark_pairs=BENCHMARK_PAIRS)\n",
    "charts.register(available_trading_pairs, ChartKind.indicator_all_pairs)\n",
    "charts.register(inclusion_criteria_check, ChartKind.indicator_all_pairs)\n",
    "charts.register(volatility_benchmark, ChartKind.indicator_multi_pair)\n",
    "charts.register(signal_comparison, ChartKind.indicator_multi_pair)\n",
    "charts.register(price_vs_signal, ChartKind.indicator_multi_pair)\n",
    "charts.register(all_vaults_share_price_and_tvl, ChartKind.indicator_all_pairs)\n",
    "charts.register(equity_curve_with_benchmark, ChartKind.state_all_pairs)\n",
    "charts.register(equity_curve_with_drawdown, ChartKind.state_all_pairs)\n",
    "charts.register(performance_metrics, ChartKind.state_all_pairs)\n",
    "charts.register(volatile_weights_by_percent, ChartKind.state_all_pairs)\n",
    "charts.register(volatile_and_non_volatile_percent, ChartKind.state_all_pairs)\n",
    "charts.register(equity_curve_by_asset, ChartKind.state_all_pairs)\n",
    "charts.register(weight_allocation_statistics, ChartKind.state_all_pairs)\n",
    "charts.register(positions_at_end, ChartKind.state_all_pairs)\n",
    "charts.register(last_messages, ChartKind.state_all_pairs)\n",
    "charts.register(alpha_model_diagnostics, ChartKind.state_all_pairs)\n",
    "charts.register(trading_pair_breakdown, ChartKind.state_all_pairs)\n",
    "charts.register(trading_metrics, ChartKind.state_all_pairs)\n",
    "charts.register(lending_pool_interest_accrued, ChartKind.state_all_pairs)\n",
    "charts.register(vault_statistics, ChartKind.state_all_pairs)\n",
    "charts.register(vault_position_timeline, ChartKind.state_single_vault_pair)\n",
    "charts.register(all_vault_positions, ChartKind.state_single_vault_pair)\n",
    "charts.register(trading_pair_positions, ChartKind.state_single_vault_pair)\n",
    "charts.register(trading_pair_price_and_trades, ChartKind.state_single_vault_pair)\n",
    "charts.register(inclusion_criteria_check, ChartKind.indicator_all_pairs)\n",
    "\n",
    "# Chart rendering pre-backtest execution\n",
    "chart_renderer = ChartBacktestRenderingSetup(\n",
    "    registry=charts,\n",
    "    strategy_input_indicators=indicator_data,\n",
    "    backtest_end_at=Parameters.backtest_end,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Available pairs\n",
    "\n",
    "- Number of pairs available to trade every month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, df = chart_renderer.render(available_trading_pairs, with_dataframe=True)\n",
    "fig.show()\n",
    "display(df.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inclusion criteria checks\n",
    "\n",
    "- Examine when different pairs got included and what was the pair status during the inclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = chart_renderer.render(inclusion_criteria_check)\n",
    "\n",
    "print(f\"First appearances of {len(df)} trading pairs, when they meet all inclusion criteria:\")\n",
    "\n",
    "with pd.option_context(\"display.float_format\", \"{:,.2f}\".format):\n",
    "    display(df.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signal comparison\n",
    "\n",
    "- Weight signal for different vaults at the moment of time\n",
    "- The signal is masked by the inclusion criteria\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take signal (pair_id, timestamp) multiindex series and get it to human-readable form\n",
    "\n",
    "# Take signal (pair_id, timestamp) multiindex series and get it to human-readable form\n",
    "rolling_returns_series = indicator_data.get_indicator_data_pairs_combined(\"rolling_returns\")\n",
    "rolling_returns_df = rolling_returns_series.unstack(level='pair_id')\n",
    "\n",
    "# Rename pair_id columns to human-readable vault/pair names\n",
    "print(\"Rolling returns:\")\n",
    "rolling_returns_df.columns = [\n",
    "    strategy_universe.get_pair_by_id(pair_id).get_ticker()\n",
    "    for pair_id in rolling_returns_df.columns\n",
    "]\n",
    "display(rolling_returns_df.tail(5))\n",
    "\n",
    "print(\"Derived signal with inclusion mask:\")\n",
    "signal_series = indicator_data.get_indicator_data_pairs_combined(\"signal\")\n",
    "signal_df = signal_series.unstack(level='pair_id')\n",
    "\n",
    "# Rename pair_id columns to human-readable vault/pair names\n",
    "signal_df.columns = [\n",
    "    strategy_universe.get_pair_by_id(pair_id).get_ticker()\n",
    "    for pair_id in signal_df.columns\n",
    "]\n",
    "\n",
    "display(signal_df.tail(5))\n",
    "\n",
    "fig = chart_renderer.render(signal_comparison)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vault TVL and share price data\n",
    "\n",
    "- Examine returns of the vaults used in this backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tradeexecutor.analysis.vault import visualise_vaults\n",
    "\n",
    "figures = chart_renderer.render(all_vaults_share_price_and_tvl)\n",
    "for fig in figures:\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time range for backtest\n",
    "\n",
    "- Choose the backtesting time range\n",
    "- Start when we have enough assets (`Parameters.min_asset_universe`) in our asset universe to form the first basket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = indicator_data.get_indicator_series(\"all_criteria_included_pair_count\")\n",
    "\n",
    "exceeds_threshold = series > Parameters.min_asset_universe\n",
    "# Get the first date where the condition is True\n",
    "backtest_start = Parameters.backtest_start\n",
    "backtest_end = Parameters.backtest_end\n",
    "\n",
    "print(f\"Time range is {backtest_start} - {backtest_end}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm and backtest\n",
    "\n",
    "- Run the backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tradeexecutor.backtest.backtest_runner import run_backtest_inline\n",
    "from tradeexecutor.strategy.alpha_model import AlphaModel\n",
    "from tradeexecutor.state.trade import TradeExecution\n",
    "from tradeexecutor.strategy.pandas_trader.strategy_input import StrategyInput, IndicatorDataNotFoundWithinDataTolerance\n",
    "from tradeexecutor.state.visualisation import PlotKind\n",
    "from tradeexecutor.backtest.backtest_runner import run_backtest_inline\n",
    "from tradeexecutor.strategy.tvl_size_risk import USDTVLSizeRiskModel\n",
    "from tradeexecutor.strategy.weighting import weight_by_1_slash_n, weight_passthrouh, weight_equal\n",
    "from tradeexecutor.utils.dedent import dedent_any\n",
    "from tradeexecutor.strategy.pandas_trader.yield_manager import YieldManager, YieldRuleset, YieldWeightingRule, YieldDecisionInput\n",
    "from tradeexecutor.strategy.execution_context import ExecutionContext, ExecutionMode\n",
    "\n",
    "\n",
    "_cached_start_times: dict[int, pd.Timestamp] = {}\n",
    "\n",
    "def create_yield_rules(\n",
    "    timestamp: pd.Timestamp,\n",
    "    parameters: StrategyParameters,\n",
    "    strategy_universe: TradingStrategyUniverse,\n",
    ") -> YieldRuleset:\n",
    "    \"\"\"Create yield rules for the strategy.\"\"\"\n",
    "    weights = []\n",
    "    for vault_spec in VAULTS:\n",
    "        vault_pair = strategy_universe.get_pair_by_smart_contract(vault_spec[1])\n",
    "        if vault_pair not in _cached_start_times:\n",
    "            price_df = strategy_universe.data_universe.candles.get_samples_by_pair(vault_pair.internal_id)\n",
    "            assert price_df is not None\n",
    "            index_entry = price_df.index[0]\n",
    "            assert isinstance(index_entry, tuple)\n",
    "            _cached_start_times[vault_pair] = index_entry[1]\n",
    "        \n",
    "        availability = _cached_start_times[vault_pair]\n",
    "        if timestamp > availability:\n",
    "            weights.append(\n",
    "            YieldWeightingRule(\n",
    "                pair=vault_pair, \n",
    "                max_concentration=1.00,\n",
    "                max_pool_participation=0.05,\n",
    "            ),\n",
    "            )\n",
    "\n",
    "    if len(weights) == 0:\n",
    "        return None\n",
    "    \n",
    "    return YieldRuleset(\n",
    "        position_allocation=parameters.allocation,\n",
    "        buffer_pct=parameters.directional_trade_yield_buffer_pct,\n",
    "        cash_change_tolerance_usd=parameters.yield_flow_dust_threshold,\n",
    "        weights=weights\n",
    "    )\n",
    "\n",
    "\n",
    "def decide_trades(\n",
    "    input: StrategyInput\n",
    ") -> list[TradeExecution]:\n",
    "    \"\"\"For each strategy tick, generate the list of trades.\"\"\"\n",
    "    parameters = input.parameters\n",
    "    position_manager = input.get_position_manager()\n",
    "    state = input.state\n",
    "    timestamp = input.timestamp\n",
    "    indicators = input.indicators\n",
    "    strategy_universe = input.strategy_universe\n",
    "\n",
    "    portfolio = position_manager.get_current_portfolio()\n",
    "    equity = portfolio.get_total_equity()\n",
    "    \n",
    "    # Live trading automation not yet enabled -\n",
    "    # manually check positions while the strategy is in beta mode\n",
    "    if input.execution_context.mode != ExecutionMode.backtesting:\n",
    "        return []\n",
    "            \n",
    "    # Build signals for each pair\n",
    "    alpha_model = AlphaModel(\n",
    "        timestamp,\n",
    "        close_position_weight_epsilon=parameters.min_portfolio_weight,  # 10 BPS is our min portfolio weight\n",
    "    )\n",
    "\n",
    "    tvl_included_pair_count = indicators.get_indicator_value(\n",
    "        \"tvl_included_pair_count\",\n",
    "    )\n",
    "\n",
    "    # Get pairs included in this rebalance cycle.\n",
    "    # This includes pair that have been pre-cleared in inclusion_criteria()\n",
    "    # with volume, volatility and TVL filters\n",
    "    included_pairs = indicators.get_indicator_value(\n",
    "        \"inclusion_criteria\",\n",
    "        na_conversion=False,\n",
    "    )\n",
    "    if included_pairs is None:\n",
    "        included_pairs = []\n",
    "\n",
    "    # Set signal for each pair\n",
    "    signal_count = 0\n",
    "    for pair_id in included_pairs:\n",
    "        pair = strategy_universe.get_pair_by_id(pair_id)\n",
    "\n",
    "        if not state.is_good_pair(pair):\n",
    "            # Tradeable flag set to False, etc.\n",
    "            continue\n",
    "\n",
    "        pair_signal = indicators.get_indicator_value(\"signal\", pair=pair)\n",
    "        if pair_signal is None:\n",
    "            continue\n",
    "\n",
    "        weight = pair_signal\n",
    "\n",
    "        if weight < 0:\n",
    "            continue\n",
    "\n",
    "        alpha_model.set_signal(\n",
    "            pair,\n",
    "            weight,\n",
    "        )\n",
    "\n",
    "        # Diagnostics reporting\n",
    "        signal_count += 1\n",
    "\n",
    "    # Calculate how much dollar value we want each individual position to be on this strategy cycle,\n",
    "    # based on our total available equity\n",
    "    portfolio = position_manager.get_current_portfolio()\n",
    "    equity = portfolio.get_total_equity()\n",
    "    portfolio_target_value = equity * parameters.allocation\n",
    "\n",
    "    alpha_model.select_top_signals(count=999)\n",
    "    alpha_model.assign_weights(method=weight_passthrouh)\n",
    "    # alpha_model.assign_weights(method=weight_by_1_slash_n)\n",
    "\n",
    "    #\n",
    "    # Normalise weights and cap the positions\n",
    "    #\n",
    "    size_risk_model = USDTVLSizeRiskModel(\n",
    "        pricing_model=input.pricing_model,\n",
    "        per_position_cap=parameters.per_position_cap_of_pool,  # This is how much % by all pool TVL we can allocate for a position\n",
    "        missing_tvl_placeholder_usd=0.0,  # Placeholder for missing TVL data until we get the data off the chain        \n",
    "    )\n",
    "\n",
    "    alpha_model.normalise_weights(\n",
    "        investable_equity=portfolio_target_value,\n",
    "        size_risk_model=size_risk_model,\n",
    "        max_weight=parameters.max_concentration,\n",
    "        max_positions=parameters.max_assets_in_portfolio,\n",
    "    )\n",
    "\n",
    "    # Load in old weight for each trading pair signal,\n",
    "    # so we can calculate the adjustment trade size\n",
    "    alpha_model.update_old_weights(\n",
    "        state.portfolio,\n",
    "        ignore_credit=False,\n",
    "    )\n",
    "    alpha_model.calculate_target_positions(position_manager)\n",
    "\n",
    "    # Shift portfolio from current positions to target positions\n",
    "    # determined by the alpha signals (momentum)\n",
    "\n",
    "    # rebalance_threshold_usd = portfolio_target_value * parameters.min_rebalance_trade_threshold_pct\n",
    "    rebalance_threshold_usd = parameters.individual_rebalance_min_threshold_usd\n",
    "\n",
    "    assert rebalance_threshold_usd > 0.1, \"Safety check tripped - something like wrong with strat code\"\n",
    "    trades = alpha_model.generate_rebalance_trades_and_triggers(\n",
    "        position_manager,\n",
    "        min_trade_threshold=rebalance_threshold_usd,  # Don't bother with trades under XXXX USD\n",
    "        invidiual_rebalance_min_threshold=parameters.individual_rebalance_min_threshold_usd,\n",
    "        sell_rebalance_min_threshold=parameters.sell_rebalance_min_threshold,\n",
    "        execution_context=input.execution_context,\n",
    "    )\n",
    "\n",
    "    # # Move cash in and out yield managed to cover spot positions\n",
    "    # yield_result = None \n",
    "    # if parameters.use_managed_yield:\n",
    "\n",
    "    #     rules = create_yield_rules(\n",
    "    #         timestamp,\n",
    "    #         parameters, \n",
    "    #         strategy_universe,\n",
    "    #     )\n",
    "\n",
    "    #     if rules is not None:\n",
    "    #         yield_manager = YieldManager(\n",
    "    #             position_manager=position_manager,\n",
    "    #             rules=rules,\n",
    "    #         )\n",
    "\n",
    "    #         yield_input = YieldDecisionInput(\n",
    "    #             execution_mode=input.execution_context.mode,\n",
    "    #             cycle=input.cycle,\n",
    "    #             timestamp=timestamp,\n",
    "    #             total_equity=state.portfolio.get_total_equity(),\n",
    "    #             directional_trades=trades,\n",
    "    #             size_risk_model=size_risk_model,\n",
    "    #             pending_redemptions=position_manager.get_pending_redemptions(),\n",
    "    #         )\n",
    "\n",
    "    #         yield_result = yield_manager.calculate_yield_management(yield_input)\n",
    "    #         trades += yield_result.trades\n",
    "        \n",
    "    # Add verbal report about decision made/not made,\n",
    "    # so it is much easier to diagnose live trade execution.\n",
    "    # This will be readable in Discord/Telegram logging.\n",
    "    if input.is_visualisation_enabled():\n",
    "        try:\n",
    "            top_signal = next(iter(alpha_model.get_signals_sorted_by_weight()))\n",
    "            if top_signal.normalised_weight == 0:\n",
    "                top_signal = None\n",
    "        except StopIteration:\n",
    "            top_signal = None\n",
    "\n",
    "        rebalance_volume = sum(t.get_value() for t in trades)\n",
    "\n",
    "        report = dedent_any(f\"\"\"\n",
    "        Cycle: #{input.cycle}\n",
    "        Rebalanced: {'ðŸ‘' if alpha_model.is_rebalance_triggered() else 'ðŸ‘Ž'}\n",
    "        Open/about to open positions: {len(state.portfolio.open_positions)} \n",
    "        Max position value change: {alpha_model.max_position_adjust_usd:,.2f} USD\n",
    "        Rebalance threshold: {alpha_model.position_adjust_threshold_usd:,.2f} USD\n",
    "        Trades decided: {len(trades)}\n",
    "        Pairs total: {strategy_universe.data_universe.pairs.get_count()}\n",
    "        Pairs meeting inclusion criteria: {len(included_pairs)}\n",
    "        Pairs meeting TVL inclusion criteria: {tvl_included_pair_count}        \n",
    "        Signals created: {signal_count}\n",
    "        Total equity: {portfolio.get_total_equity():,.2f} USD\n",
    "        Cash: {position_manager.get_current_cash():,.2f} USD\n",
    "        Target value: {portfolio_target_value:,.2f} USD\n",
    "        Investable equity: {alpha_model.investable_equity:,.2f} USD\n",
    "        Accepted investable equity: {alpha_model.accepted_investable_equity:,.2f} USD\n",
    "        Allocated to signals: {alpha_model.get_allocated_value():,.2f} USD\n",
    "        Discarted allocation because of lack of lit liquidity: {alpha_model.size_risk_discarded_value:,.2f} USD\n",
    "        Rebalance volume: {rebalance_volume:,.2f} USD\n",
    "        \"\"\")\n",
    "\n",
    "        # Most volatility pair signal weight (normalised): {max_vol_signal.normalised_weight * 100 if max_vol_signal else '-'} % (got {max_vol_signal.position_size_risk.get_relative_capped_amount() * 100 if max_vol_signal else '-'} % of asked size)\n",
    "        if top_signal:\n",
    "            assert top_signal.position_size_risk\n",
    "            report += dedent_any(f\"\"\"\n",
    "            Top signal pair: {top_signal.pair.get_ticker()}\n",
    "            Top signal value: {top_signal.signal}\n",
    "            Top signal weight: {top_signal.raw_weight}\n",
    "            Top signal weight (normalised): {top_signal.normalised_weight * 100:.2f} % (got {top_signal.position_size_risk.get_relative_capped_amount() * 100:.2f} % of asked size)\n",
    "            \"\"\")\n",
    "\n",
    "        for flag, count in alpha_model.get_flag_diagnostics_data().items():\n",
    "            report += f\"Signals with flag {flag.name}: {count}\\n\"\n",
    "\n",
    "        state.visualisation.add_message(\n",
    "            timestamp,\n",
    "            report,\n",
    "        )\n",
    "\n",
    "        state.visualisation.set_discardable_data(\"alpha_model\", alpha_model)\n",
    "\n",
    "    return trades  # Return the list of trades we made in this cycle\n",
    "\n",
    "\n",
    "result = run_backtest_inline(\n",
    "    name=parameters.id,\n",
    "    engine_version=\"0.5\",\n",
    "    decide_trades=decide_trades,\n",
    "    create_indicators=indicators.create_indicators,\n",
    "    client=client,\n",
    "    universe=strategy_universe,\n",
    "    parameters=parameters,\n",
    "    # log_level=logging.INFO,\n",
    "    max_workers=1,\n",
    "    start_at=backtest_start,\n",
    "    end_at=backtest_end,\n",
    ")\n",
    "\n",
    "state = result.state\n",
    "\n",
    "all_trades = list(state.portfolio.get_all_trades())\n",
    "trade_count = len(all_trades)\n",
    "print(f\"Backtesting completed, backtested strategy made {trade_count} trades, {state.cycle} cycles executed, last cycle at {state.last_cycle_at} w/ open positions {state.last_open_positions_cycle_at}\")\n",
    "if len(all_trades) > 0:\n",
    "    print(f\"First trade at {all_trades[0].executed_at}, last trade at {all_trades[-1].executed_at}\")\n",
    "\n",
    "# Add state to the further charts\n",
    "chart_renderer = ChartBacktestRenderingSetup(\n",
    "    registry=charts,\n",
    "    strategy_input_indicators=indicator_data,\n",
    "    state=state,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance metrics\n",
    "\n",
    "- Display portfolio performance metrics\n",
    "- Compare against buy and hold matic using the same initial capital\n",
    "\n",
    "**Note**: Some of these metrics might be incorrect due to slow start of the strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tradeexecutor.analysis.multi_asset_benchmark import compare_strategy_backtest_to_multiple_assets\n",
    "\n",
    "df = chart_renderer.render(performance_metrics)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equity curve\n",
    "\n",
    "- Equity curve shows how your strategy accrues value over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = chart_renderer.render(\n",
    "    equity_curve_with_benchmark, \n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equity curve with drawdown\n",
    "\n",
    "- Linear curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = chart_renderer.render(equity_curve_with_drawdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asset weights\n",
    "\n",
    "- What assets were allocated over time\n",
    "- Do both proportional % and USD weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volatiles only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = chart_renderer.render(volatile_weights_by_percent)\n",
    "# fig.show()\n",
    "\n",
    "print(\"Currently the strategy does not take directional positions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volatiles and non-volatiles\n",
    "\n",
    "- Portfolio with cash, lending and vault positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = chart_renderer.render(volatile_and_non_volatile_percent)\n",
    "fig.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio equity curve breakdown by asset\n",
    "\n",
    "- Where did we make the profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = chart_renderer.render(equity_curve_by_asset)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight allocation statistics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = chart_renderer.render(weight_allocation_statistics)\n",
    "display(stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positions at the end\n",
    "\n",
    "Some example positions at the end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = chart_renderer.render(positions_at_end)\n",
    "display(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategy thinking\n",
    "\n",
    "- At the end of strategy\n",
    "- Reverse order - last timestamp first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = chart_renderer.render(last_messages)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alpha model diagnostics data\n",
    "\n",
    "- Dump out alpha model contents from the last cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = chart_renderer.render(alpha_model_diagnostics)\n",
    "display(df)\n",
    "\n",
    "print(\"Total asked:\", df[\"Asked size\"].replace(\"-\", float(\"nan\")).dropna().sum())\n",
    "print(\"Total accepted:\", df[\"Accepted size\"].dropna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trading pair breakdown\n",
    "\n",
    "- Trade success for each trading pair\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = chart_renderer.render(trading_pair_breakdown)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trading metrics\n",
    "\n",
    "- Trading cost, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = chart_renderer.render(trading_metrics)\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interest accrued\n",
    "\n",
    "- How much profit our non-volatile positions generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lending pools\n",
    "\n",
    "- Calculate interest from lending pools (Aave, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = chart_renderer.render(lending_pool_interest_accrued)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vault performance\n",
    "\n",
    "- Analyse the performance of our vaults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vault statistics \n",
    "\n",
    "- Calculate interest accrued on different vaults for the strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = chart_renderer.render(vault_statistics)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vault position list\n",
    "\n",
    "- Display individual positions taken in the vaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = chart_renderer.render(all_vault_positions)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vault individual position timeline\n",
    "\n",
    "- Show one of the vaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = strategy_universe.get_pair_by_smart_contract(address=VAULTS[0][1])\n",
    "\n",
    "chart_renderer = ChartBacktestRenderingSetup(\n",
    "    registry=charts,\n",
    "    strategy_input_indicators=indicator_data,\n",
    "    pairs=[pair],\n",
    "    state=state,\n",
    ")\n",
    "\n",
    "fig, df = chart_renderer.render(vault_position_timeline)\n",
    "\n",
    "if fig is not None:\n",
    "    display(fig)\n",
    "\n",
    "if df is not None:\n",
    "    display(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
